{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ad7f6c",
   "metadata": {},
   "source": [
    "# Week 3 - Training\n",
    "\n",
    "Now that we have the shape of our general purpose curve fitting function, how do we train them?\n",
    "\n",
    "* What is training?\n",
    "* Gradient descent\n",
    "* Stochastic Gradient descent\n",
    "* Train/test split\n",
    "* Learning curves\n",
    "* Hyperparameters \n",
    "    * Numebr of layers\n",
    "    * Size of each layer\n",
    "* Dropout\n",
    "* L1/L2 regularization    \n",
    "* Train our first network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57c6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f95acb",
   "metadata": {},
   "source": [
    "## What is Training\n",
    "\n",
    "In the last lesson, we talked about the structure of neural networks as mathematical functions.\n",
    "We learned that neural networks satisfy the universal approximation theorem, meaning that with a good choice of parameters they can approximate _any_ function.\n",
    "This week, we will discuss _how_ we can find the best values for the weights and biases so that the neural network fits whatever data we like.\n",
    "The process of finding the best parameters is called **training.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c1b57",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "TODO\n",
    "\n",
    "### Loss Functions for Classification and Regression\n",
    "\n",
    "## Stochastic Gradient Descent\n",
    "\n",
    "TODO\n",
    "\n",
    "## Training a Neural Network with Keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c2088",
   "metadata": {},
   "source": [
    "# Homework Questions\n",
    "\n",
    "1. Describe the difference between standard gradient descent and stochastic gradient descent.\n",
    "Explain the advantages of using stochastic gradient descent.\n",
    "\n",
    "2. Explain what the purpose of a loss function is. Describe two loss functions we learned about and what the use cases would be for each.\n",
    "\n",
    "3. Use the Pandas library to load the given dataset. Use the `train_test_split` function to split the data into training and testing datasets with 80% for training and 20% for testing.\n",
    "\n",
    "4. Use the Keras library's `Sequential` model to build a simple neural network with one hidden layer with 100 neurons. Train the model to predict the column `___NAME___`. Evaluate the neural network on the test data you created in question 2.\n",
    "\n",
    "5. Use learning curves to determine if the neural network from question \\#4 is underfitting or overfitting. Explain your reasoning.\n",
    "\n",
    "6. Try to improve the neural network you trained in question \\#4 above by including regularization, dropout, or by varying the number or size of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4304c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_374",
   "language": "python",
   "name": "comp_374"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
