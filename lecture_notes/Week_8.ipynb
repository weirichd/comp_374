{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4958cbd5-f91b-4b86-b013-1ccac4a8e0a9",
   "metadata": {},
   "source": [
    "# Module 8: Attention and Transformer Architecture\n",
    "\n",
    "This week we will be working to implement a simple attention based model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b67d3e7-3c5b-4d9b-9670-4f832ceb0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ea5c1-d9b5-4440-b7ac-fa7372e609b8",
   "metadata": {},
   "source": [
    "## A Note About Computation\n",
    "\n",
    "Transformers are some of the most complicated models which we have studied yet - both in terms of the model architecture as well as in terms of the computational power required to train them.\n",
    "In the real world, transformers are typically require very large training sets with and can be quite expensive to train.\n",
    "\n",
    "In this class, we won't have access to supercomputing clusters to train our models, so we will have to make due with small examples.\n",
    "This means that the models we end up creating might not be as performant as we would like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578d789-16b2-4b6d-8dd1-424f7bc03fe2",
   "metadata": {},
   "source": [
    "## Tweets Data\n",
    "\n",
    "In this lesson we will be using a dataset consisting of tweets.\n",
    "\n",
    "> **Dataset source:**\n",
    "> \n",
    ">  Bin Tareaf, Raad, 2017, \"Tweets Dataset - Top 20 most followed users in Twitter social platform\", https://doi.org/10.7910/DVN/JBXKFD, Harvard Dataverse, V2\n",
    ">\n",
    "> https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/JBXKFD\n",
    "\n",
    "This dataset consists of 52k tweets by the top 20 most popular users by follower count (as of Nov. 2017)\n",
    "\n",
    "Tweets make nice data inputs since they are always short!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcf8133-99d1-455e-9f8f-0565f958890e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>country</th>\n",
       "      <th>date_time</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_likes</th>\n",
       "      <th>number_of_shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49321</th>\n",
       "      <td>instagram</td>\n",
       "      <td>Celebrating motherhood every day with illustra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08/05/2016 17:30</td>\n",
       "      <td>7.293630e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1661</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14504</th>\n",
       "      <td>YouTube</td>\n",
       "      <td>@IamLeroySanchez Congratulations! 2 million su...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/06/2016 22:18</td>\n",
       "      <td>7.428440e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45431</th>\n",
       "      <td>shakira</td>\n",
       "      <td>\"Los ni침os m치s adorables bailando 'La Biciclet...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/08/2016 11:38</td>\n",
       "      <td>7.637010e+17</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2119</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23632</th>\n",
       "      <td>jtimberlake</td>\n",
       "      <td>Proud this is happening in Franklin, #Tennesse...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13/09/2016 20:33</td>\n",
       "      <td>7.757940e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>BarackObama</td>\n",
       "      <td>NASA leads the world in the exploration and st...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/05/2015 23:05</td>\n",
       "      <td>5.979000e+17</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1762</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                            content country  \\\n",
       "49321    instagram  Celebrating motherhood every day with illustra...     NaN   \n",
       "14504      YouTube  @IamLeroySanchez Congratulations! 2 million su...     NaN   \n",
       "45431      shakira  \"Los ni침os m치s adorables bailando 'La Biciclet...     NaN   \n",
       "23632  jtimberlake  Proud this is happening in Franklin, #Tennesse...     NaN   \n",
       "8685   BarackObama  NASA leads the world in the exploration and st...     NaN   \n",
       "\n",
       "              date_time            id language  latitude  longitude  \\\n",
       "49321  08/05/2016 17:30  7.293630e+17       en       NaN        NaN   \n",
       "14504  14/06/2016 22:18  7.428440e+17       en       NaN        NaN   \n",
       "45431  11/08/2016 11:38  7.637010e+17       es       NaN        NaN   \n",
       "23632  13/09/2016 20:33  7.757940e+17       en       NaN        NaN   \n",
       "8685   11/05/2015 23:05  5.979000e+17       en       NaN        NaN   \n",
       "\n",
       "       number_of_likes  number_of_shares  \n",
       "49321             1661               484  \n",
       "14504              168                66  \n",
       "45431             2119               405  \n",
       "23632             1958               394  \n",
       "8685              1762               997  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data = pd.read_csv('../data/tweets.csv')\n",
    "\n",
    "# What does this dataset look like?\n",
    "tweets_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79cea983-b0d1-41bc-a741-b1c2085eec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Tweet Counts'}, xlabel='author'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Who is tweeting?\n",
    "\n",
    "tweets_data['author'].value_counts().plot(\n",
    "    kind='bar', figsize=(10, 4), title='Tweet Counts'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3809e97b-830b-4cd8-aa6d-e16a0db74503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter\n",
      "Please read the status blog for information if you are missing tweets in your timeline: http://bit.ly/cHJB9w\n",
      "\n",
      "---\n",
      "\n",
      "ladygaga\n",
      "When your up at 5 am because you wanna make sure you don't forget to download @IronMaiden new album The Book of Souls. MUSIC FANDOM IS ALIVE\n",
      "\n",
      "---\n",
      "\n",
      "ladygaga\n",
      "My manager @bobby_campbell made Billboard's #40Under40 Power Players List. I wouldn't be where I am today without him http://t.co/84L7RiX5cg\n",
      "\n",
      "---\n",
      "\n",
      "YouTube\n",
      "I have a trend. \n",
      "I have a video. \n",
      "UGHN!\n",
      "Trending Video. \n",
      "\n",
      "2016뗩 most viral  https://t.co/qCf2LeabAo https://t.co/QLebXxA9FG\n",
      "\n",
      "---\n",
      "\n",
      "Twitter\n",
      "@captnchedz Happy birthday, here's another! https://t.co/XWZIuquqVt\n",
      "\n",
      "---\n",
      "\n",
      "Cristiano\n",
      "Hey @Tuurryy impressive play with the @Nikefootball App! These are on their way to you! 游땙游녨 https://t.co/tXAjIBbTCZ https://t.co/jrYaqKFzlm\n",
      "\n",
      "---\n",
      "\n",
      "jtimberlake\n",
      "Let me know who you all think is your favorite \"Not A Bad Love Story\"! I want to surprise em! http://t.co/XcpVQvA4z2\n",
      "\n",
      "---\n",
      "\n",
      "Cristiano\n",
      "You asked: Hi Cristiano, can you say me \"Ciao Miriam\"! You're my idol and I'm your biggest fan from Italy! http://t.co/GNAWVy2VtW\n",
      "\n",
      "---\n",
      "\n",
      "taylorswift13\n",
      "\"Your little hand's wrapped around my finger and it's so quiet in the world tonight...\" http://t.co/nGaWkKHmJk\n",
      "\n",
      "---\n",
      "\n",
      "BarackObama\n",
      "\"The freedom to marry who you love닶hat's now open to all of us. That's a good thing.\" President Obama #LoveWins\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some tweets:\n",
    "\n",
    "N_TWEETS_TO_VIEW = 10\n",
    "\n",
    "for _, row in tweets_data.sample(N_TWEETS_TO_VIEW).iterrows():\n",
    "    print(f\"{row['author']}\\n{row['content']}\")\n",
    "    print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19315ee-b2cb-4676-924f-e72b266148dd",
   "metadata": {},
   "source": [
    "Our goal will be to create a model which will attempt to read a tweet and determine who the author is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f188eb4-100f-48e7-a29b-d7051c2c183d",
   "metadata": {},
   "source": [
    "## Embedding Layers in Keras\n",
    "\n",
    "We kick things off today with embedding layers! In the last module, we implemented our example embedding as a simple Python dictionary.\n",
    "Inside the transformer, we can instead use the [keras embedding layer](https://keras.io/api/layers/core_layers/embedding/).\n",
    "\n",
    "\n",
    "### Training Embeddings\n",
    "\n",
    "Embeddings, like any other data structure, need to be trained to be useful.\n",
    "\n",
    "There are two main ways to train embedding layers:\n",
    "\n",
    "*  **Standard Training with Backpropagation**\n",
    "    - An embedding matrix is initialized with random values.\n",
    "    - During training, backpropagation updates the embeddings based on the loss function.\n",
    "    - The updates come from the gradient of the loss with respect to the embedding weights.\n",
    "    - Over time, the embeddings learn to map similar words closer together.\n",
    "*  **Learning via Word Co-Occurrence (Pretraining)**\n",
    "    - If two words frequently appear in similar contexts (e.g., 띿og and 랋uppy), their embeddings become closer.\n",
    "    - The model learns embeddings that maximize classification accuracy or some other objective.\n",
    "\n",
    "For now, we will stick with the standard approach.\n",
    "\n",
    "### Our Embedding\n",
    "\n",
    "To keep things simple, we will use the method of encoding each _unique character_.\n",
    "Normally, you would perfer to encode words, but encoding characters allows us to simplify things for this lesson.\n",
    "\n",
    "Let's begin by pre-processing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3403307-cd3a-419d-b6f5-e6df6a56dee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1037"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a character-level tokenizer\n",
    "tokenizer = Tokenizer(char_level=True)  # Tokenize at character level\n",
    "tokenizer.fit_on_texts(tweets_data['content'])\n",
    "\n",
    "# Convert text into sequences\n",
    "sequences = tokenizer.texts_to_sequences(tweets_data['content'])\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "# Pad sequences for uniform input size\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Get vocabulary size (including padding token)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # +1 for padding index 0\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e9e6df0-d103-4f34-98ed-54e85eb40224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   6,   1, ...,   0,   0,   0],\n",
       "       [ 28,  23,   5, ...,   0,   0,   0],\n",
       "       [ 11,   7,  22, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [ 12,  10,   7, ...,   0,   0,   0],\n",
       "       [148,  56,   1, ...,   0,   0,   0],\n",
       "       [ 62,  56, 148, ...,   0,   0,   0]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This contains the encoded tweets\n",
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4ae254-a1ea-400c-a67c-c8ded4efa72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 152, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 12  # Size of embedding vectors\n",
    "\n",
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=EMBEDDING_SIZE,\n",
    ")\n",
    "\n",
    "# Look at the embedding output for the first 4 tweets:\n",
    "emb_output = embedding_layer(padded_sequences[:4]).numpy()\n",
    "\n",
    "emb_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75fcfef-0287-4c81-ad27-38b11ad7269b",
   "metadata": {},
   "source": [
    "We can see that this embedding layer is outputing a 3D tensor.\n",
    "Let's make sure we totally understand what we are seeing here:\n",
    "\n",
    "* Axis 0: The sample axis\n",
    "* Axis 1: The character axis\n",
    "* Axis 2: The embedding axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2bd7c2-cca6-413f-84b5-61ba515c1375",
   "metadata": {},
   "source": [
    "## Self Attention\n",
    "\n",
    "In the last lesson, we learned about how the attention calculation worked, using a query, key, and value matrices:\n",
    "\n",
    "$$\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$\n",
    "\n",
    "The special case where $Q$, $K$, and $V$ are all the same matrix is called _self attention_.\n",
    "We do this when we want each token in the input to pay attention to every other token in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3930607-2c93-4ad0-9de8-0ee331f77712",
   "metadata": {},
   "source": [
    "## Attention Layer in Keras\n",
    "\n",
    "Let's get started by now creating the simplist transformer model possible.\n",
    "\n",
    "Note that the `Attention` layer has _two_ required inputs, so we are not able to use the `Sequential` API here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a646c5-3d3c-4dd3-9577-2c2b283dae67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
       "較<span style=\"font-weight: bold\"> Layer (type)        </span>較<span style=\"font-weight: bold\"> Output Shape      </span>較<span style=\"font-weight: bold\">    Param # </span>較<span style=\"font-weight: bold\"> Connected to      </span>較\n",
       "較뫡대較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較뼆n",
       "較 input_layer         較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>)       較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 -                 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 embedding_1         較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   較     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,444</span> 較 input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 attention           較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         較                   較            較 embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalization 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> 較 attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> 較 layer_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 global_average_poo 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        較      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> 較 global_average_p 較\n",
       "較덕較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較\n",
       "</pre>\n"
      ],
      "text/plain": [
       "較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
       "較\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m較\n",
       "較뫡대較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較뼆n",
       "較 input_layer         較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m)       較          \u001b[38;5;34m0\u001b[0m 較 -                 較\n",
       "較 (\u001b[38;5;33mInputLayer\u001b[0m)        較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 embedding_1         較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m12\u001b[0m)   較     \u001b[38;5;34m12,444\u001b[0m 較 input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] 較\n",
       "較 (\u001b[38;5;33mEmbedding\u001b[0m)         較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 attention           較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m12\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m 較\n",
       "較 (\u001b[38;5;33mAttention\u001b[0m)         較                   較            較 embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalization 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m12\u001b[0m)   較         \u001b[38;5;34m24\u001b[0m 較 attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense (\u001b[38;5;33mDense\u001b[0m)       較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m64\u001b[0m)   較        \u001b[38;5;34m832\u001b[0m 較 layer_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m64\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 global_average_poo 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        較          \u001b[38;5;34m0\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mGlobalAveragePool뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_1 (\u001b[38;5;33mDense\u001b[0m)     較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        較      \u001b[38;5;34m1,300\u001b[0m 較 global_average_p 較\n",
       "較덕較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,728</span> (57.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,728\u001b[0m (57.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,728</span> (57.53 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,728\u001b[0m (57.53 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define input layer\n",
    "inputs = layers.Input(shape=(max_length,))\n",
    "\n",
    "# Embedding layer\n",
    "embedding = layers.Embedding(input_dim=vocab_size, output_dim=EMBEDDING_SIZE)(inputs)\n",
    "\n",
    "# Self-attention layer (query = value = embedding)\n",
    "attention = layers.Attention(dropout=.1)([embedding, embedding])\n",
    "\n",
    "# Perform Layer Normalization for Training Stability\n",
    "attention_norm = layers.LayerNormalization(epsilon=1e-6)(attention)\n",
    "\n",
    "# Dense layer\n",
    "dense = layers.Dense(64, activation=\"relu\")(attention_norm)\n",
    "\n",
    "# Perform Layer Normalization for Training Stability\n",
    "dense_norm = layers.LayerNormalization(epsilon=1e-6)(dense)\n",
    "\n",
    "# Pool across tokens\n",
    "pooled_output = layers.GlobalAveragePooling1D()(dense_norm)\n",
    "\n",
    "# Output layer (multi-class classification, 20 classes)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(pooled_output)\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),  # Lowered learning rate for stability\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ecd3890-812c-4359-83a1-df35122e748b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "# Create the target vector\n",
    "label_names = tweets_data['author'].unique()\n",
    "\n",
    "# Convert string labels to integer indices\n",
    "label_mapping = tf.keras.layers.StringLookup(vocabulary=label_names)\n",
    "y_train = tf.constant(tweets_data['author'])\n",
    "y_train_encoded = label_mapping(y_train)\n",
    "\n",
    "# Fix off-by-one errors that the StringLookup creates\n",
    "y_train_encoded = y_train_encoded - 1\n",
    "\n",
    "print(y_train_encoded.numpy())  # Output: array of integer indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3817fd-bc47-422b-8bf2-2c460c6712db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20), dtype=float32, numpy=\n",
       "array([[0.0325825 , 0.00341011, 0.00589292, 0.0027805 , 0.13329884,\n",
       "        0.01171823, 0.00196772, 0.01237508, 0.08053779, 0.00950102,\n",
       "        0.1962702 , 0.0972658 , 0.02377292, 0.33706576, 0.00218757,\n",
       "        0.00936486, 0.01625931, 0.01866165, 0.00225289, 0.0028344 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the model outputs reasonably shapped results before trying to train \n",
    "model(padded_sequences[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b9d81-bf6f-4e1a-ba6b-3c0f1cad3af5",
   "metadata": {},
   "source": [
    "Let's train the model! To simplifying things in this lesson we will only use a training set and not worry about a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b77a055b-c118-45b9-b9ea-47e6fd43d45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1739812845.573105     658 service.cc:146] XLA service 0x7f717c0357d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1739812845.573138     658 service.cc:154]   StreamExecutor device (0): Quadro RTX 5000, Compute Capability 7.5\n",
      "I0000 00:00:1739812845.573143     658 service.cc:154]   StreamExecutor device (1): Quadro RTX 5000, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  99/1642\u001b[0m \u001b[32m較\u001b[0m\u001b[37m較較較較較較較較較較較較較較較較較較較\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.0567 - loss: 3.5300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1739812848.003864     658 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1087 - loss: 2.9733\n",
      "Epoch 2/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2737 - loss: 2.4049\n",
      "Epoch 3/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3318 - loss: 2.2319\n",
      "Epoch 4/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3585 - loss: 2.1399\n",
      "Epoch 5/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3773 - loss: 2.0827\n",
      "Epoch 6/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3916 - loss: 2.0280\n",
      "Epoch 7/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4041 - loss: 1.9978\n",
      "Epoch 8/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4136 - loss: 1.9561\n",
      "Epoch 9/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4231 - loss: 1.9304\n",
      "Epoch 10/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4231 - loss: 1.9135\n",
      "Epoch 11/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4383 - loss: 1.8829\n",
      "Epoch 12/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4395 - loss: 1.8668\n",
      "Epoch 13/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4438 - loss: 1.8547\n",
      "Epoch 14/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4479 - loss: 1.8373\n",
      "Epoch 15/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4496 - loss: 1.8363\n",
      "Epoch 16/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4483 - loss: 1.8321\n",
      "Epoch 17/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4529 - loss: 1.8140\n",
      "Epoch 18/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4536 - loss: 1.8082\n",
      "Epoch 19/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4577 - loss: 1.7970\n",
      "Epoch 20/20\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4596 - loss: 1.7976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f7339965610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sequences, y_train_encoded, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4252b51-d08d-4f27-9217-fc4ae7afa1e4",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "\n",
    "The initial model was able to achieve a training accuracy of around 46%, which all things considered isn't too bad.\n",
    "Let's now add a few improvements.\n",
    "\n",
    "### Positional Information with Sinusoidal Positional Encoding\n",
    "\n",
    "Transformers lack recurrence and convolution, meaning they do not inherently understand the order of tokens in a sequence. Since word order is crucial for understanding meaning (e.g., \"The cat chased the dog\" vs. \"The dog chased the cat\"), we need a way to encode position information into the input embeddings.\n",
    "\n",
    "Positional encodings provide a way to inject sequential information into token embeddings while keeping the model fully differentiable.\n",
    "\n",
    "#### How Sinusoidal Encoding Works\n",
    "\n",
    "Instead of learning position embeddings (as in some transformer variations), the original Transformer paper (\"Attention is All You Need\", Vaswani et al. 2017) used a fixed sinusoidal function. This approach ensures:\n",
    "\n",
    "* The encoding generalizes to sequences longer than those seen during training.\n",
    "* The model can learn relative positions rather than absolute positions.\n",
    "\n",
    "For a given position $pos$ and embedding dimension $i$, the encoding is defined as:\n",
    "\n",
    "$$PE_{pos,2i} = \\sin멮\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$\n",
    "$$PE_{pos,2i+1} = \\cos멮\left(\\frac{pos}{10000^{2i/d_{model}}}\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $pos$ is the position in the sequence.\n",
    "* $i$ is the dimension index within the embedding vector.\n",
    "* $d_{model}$ is the total embedding size\n",
    "* 10000 is a scaling factor to spread out the values across dimensions.\n",
    "\n",
    "#### Why Use Sin and Cos Functions?\n",
    "\n",
    "* Smooth Variation  Nearby positions have similar encodings, allowing the model to interpolate positions smoothly.\n",
    "* Uniqueness  Each position has a unique encoding due to the combination of sine and cosine functions.\n",
    "* Relative Positioning  The encoding allows the model to infer relative positions (e.g., \"word X is five steps ahead of word Y\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ebbf9ee-7f0e-4c73-b3db-499115210304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we implement this layer ourselves\n",
    "# We could also use https://keras.io/keras_hub/api/modeling_layers/sine_position_encoding/\n",
    "# if we had the keras_hub package installed\n",
    "\n",
    "class SinePositionalEncoding(layers.Layer):\n",
    "    \"\"\"Custom Layer to implement the sinusoidal positional information.\"\"\"\n",
    "    \n",
    "    def __init__(self, sequence_length: int, d_model: int):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "        self.d_model = d_model\n",
    "        self.pos_encoding = self._compute_positional_encoding()\n",
    "\n",
    "    def _compute_positional_encoding(self):\n",
    "        positions = np.arange(self.sequence_length)[:, np.newaxis]  # Shape: (seq_length, 1)\n",
    "        div_term = np.exp(np.arange(0, self.d_model, 2) * (-np.log(10000.0) / self.d_model))\n",
    "\n",
    "        pos_encoding = np.zeros((self.sequence_length, self.d_model))\n",
    "        pos_encoding[:, 0::2] = np.sin(positions * div_term)\n",
    "        pos_encoding[:, 1::2] = np.cos(positions * div_term)\n",
    "\n",
    "        return tf.cast(pos_encoding[np.newaxis, ...], dtype=tf.float32)  # Shape: (1, seq_length, d_model)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f10b0d-70d7-469e-b2b1-2fe2b56529f9",
   "metadata": {},
   "source": [
    "### Multihead Attention\n",
    "\n",
    "Up until now, our model only contains one attention \"head\".\n",
    "What this means is that we are only able to calculate one kind of attention relationship for each embedding vector.\n",
    "However, in real language there are often multiple contexts that need to be taken into account.\n",
    "Consider\n",
    "\n",
    "> I do not own a red hat.\n",
    "\n",
    "Here, the work \"hat\" should be paying attetion to both the word \"red\" as an adjective, as well as the word \"not\" meaning negation.\n",
    "\n",
    "To achieve this improvement, we replace our `Attention` layers with `MultiHeadAttention` layers.\n",
    "\n",
    "\n",
    "### Residual Connections\n",
    "\n",
    "A residual connection (or skip connection) is a technique where the input to a layer is added back to the layer's output. This helps with gradient flow, stabilizing deep networks.\n",
    "\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "Batch normalization can improve gradient stability and speed up training.\n",
    "\n",
    "### Add more depth!\n",
    "\n",
    "The last improvement we can make is to add more total attention layers.\n",
    "This allows our model to properly learn higher level relationships, at the cost of training computational complexity.\n",
    "This should be particularly helpful to our model since we are using character-embeddings instead of word-embeddings.\n",
    "\n",
    "Let's update our model building code and see how things improve!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45e69a73-858e-4b11-8f96-25e454f70c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
       "較<span style=\"font-weight: bold\"> Layer (type)        </span>較<span style=\"font-weight: bold\"> Output Shape      </span>較<span style=\"font-weight: bold\">    Param # </span>較<span style=\"font-weight: bold\"> Connected to      </span>較\n",
       "較뫡대較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較뼆n",
       "較 input_layer_10      較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>)       較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 -                 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 embedding_11        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,184</span> 較 input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 sine_positional_en 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 embedding_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SinePositionalEnc</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> 較 sine_positional_ 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span> 較                   較            較 sine_positional_ 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 sine_positional_ 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> 較 dense_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> 較 batch_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span> 較                   較            較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> 較 dense_35[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,800</span> 較 batch_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio</span> 較                   較            較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> 較 dense_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> 較 add_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   較        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> 較 layer_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 global_average_poo 較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        較          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> 較 batch_normalizat 較\n",
       "較 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool</span> 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    較 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        較        <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> 較 global_average_p 較\n",
       "較덕較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較\n",
       "</pre>\n"
      ],
      "text/plain": [
       "較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較較늎n",
       "較\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m較\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m較\n",
       "較뫡대較較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較轎較較較較較較較較較較較較轎較較較較較較較較較較較較較較較較較較較較뼆n",
       "較 input_layer_10      較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m)       較          \u001b[38;5;34m0\u001b[0m 較 -                 較\n",
       "較 (\u001b[38;5;33mInputLayer\u001b[0m)        較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 embedding_11        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較     \u001b[38;5;34m33,184\u001b[0m 較 input_layer_10[\u001b[38;5;34m0\u001b[0m 較\n",
       "較 (\u001b[38;5;33mEmbedding\u001b[0m)         較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 sine_positional_en 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 embedding_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m뵢u001b[0m 較\n",
       "較 (\u001b[38;5;33mSinePositionalEnc뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較     \u001b[38;5;34m16,800\u001b[0m 較 sine_positional_ 較\n",
       "較 (\u001b[38;5;33mMultiHeadAttentio뵢u001b[0m 較                   較            較 sine_positional_ 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_25 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 sine_positional_ 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_33 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m128\u001b[0m)  較      \u001b[38;5;34m4,224\u001b[0m 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_34 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較      \u001b[38;5;34m4,128\u001b[0m 較 dense_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_26 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較     \u001b[38;5;34m16,800\u001b[0m 較 batch_normalizat 較\n",
       "較 (\u001b[38;5;33mMultiHeadAttentio뵢u001b[0m 較                   較            較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_27 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_35 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m128\u001b[0m)  較      \u001b[38;5;34m4,224\u001b[0m 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_36 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較      \u001b[38;5;34m4,128\u001b[0m 較 dense_35[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_28 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 multi_head_attenti 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較     \u001b[38;5;34m16,800\u001b[0m 較 batch_normalizat 較\n",
       "較 (\u001b[38;5;33mMultiHeadAttentio뵢u001b[0m 較                   較            較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_29 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較                     較                   較            較 multi_head_atten 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_37 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m128\u001b[0m)  較      \u001b[38;5;34m4,224\u001b[0m 較 batch_normalizat 較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_38 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較      \u001b[38;5;34m4,128\u001b[0m 較 dense_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 add_30 (\u001b[38;5;33mAdd\u001b[0m)        較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較                     較                   較            較 dense_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 layer_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較         \u001b[38;5;34m64\u001b[0m 較 add_30[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      較\n",
       "較 (\u001b[38;5;33mLayerNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 batch_normalizatio 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m152\u001b[0m, \u001b[38;5;34m32\u001b[0m)   較        \u001b[38;5;34m128\u001b[0m 較 layer_normalizat 較\n",
       "較 (\u001b[38;5;33mBatchNormalizatio뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 global_average_poo 較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        較          \u001b[38;5;34m0\u001b[0m 較 batch_normalizat 較\n",
       "較 (\u001b[38;5;33mGlobalAveragePool뵢u001b[0m 較                   較            較                   較\n",
       "較럭較較較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較쩍較較較較較較較較較較較較쩍較較較較較較較較較較較較較較較較較較較\n",
       "較 dense_39 (\u001b[38;5;33mDense\u001b[0m)    較 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)        較        \u001b[38;5;34m660\u001b[0m 較 global_average_p 較\n",
       "較덕較較較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較억較較較較較較較較較較較較억較較較較較較較較較較較較較較較較較較較\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,452</span> (431.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m110,452\u001b[0m (431.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">110,068</span> (429.95 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m110,068\u001b[0m (429.95 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updated model with all the improvements\n",
    "\n",
    "# Define hyperparameters\n",
    "EMBEDDING_SIZE = 32 # Embedding layer size\n",
    "SEQ_LENGTH = 50     # Number of tokens in each input sequence\n",
    "NUM_HEADS = 4       # Number of attention heads\n",
    "NUM_LAYERS = 3      # Number of transformer layers\n",
    "DFF = 128           # Size of feedforward network\n",
    "\n",
    "# Define input layer\n",
    "inputs = tf.keras.Input(shape=(max_length,))\n",
    "\n",
    "# Embedding layer with mask support\n",
    "embedding = layers.Embedding(input_dim=vocab_size, output_dim=EMBEDDING_SIZE)(inputs)\n",
    "\n",
    "# Built-in Keras sinusoidal positional encoding\n",
    "pos_encoding = SinePositionalEncoding(sequence_length=max_length, d_model=EMBEDDING_SIZE)(embedding)\n",
    "\n",
    "# Transformer Encoder Block\n",
    "x = pos_encoding\n",
    "\n",
    "for _ in range(NUM_LAYERS):\n",
    "    # Multi-Head Attention\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=NUM_HEADS, key_dim=EMBEDDING_SIZE)(x, x)\n",
    "    \n",
    "    # Residual connection and normalization\n",
    "    x = layers.Add()([x, attn_output])  \n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Feedforward layer\n",
    "    ffn = layers.Dense(DFF, activation=\"relu\")(x)\n",
    "    ffn = layers.Dense(EMBEDDING_SIZE)(ffn)\n",
    "    \n",
    "    # Residual connection and normalization\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "# Global pooling\n",
    "pooled_output = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "# Output layer (20 classes)\n",
    "outputs = layers.Dense(20, activation=\"softmax\")(pooled_output)\n",
    "\n",
    "# Define and compile model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff29584a-40a6-432f-b22c-2032db240eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 12ms/step - accuracy: 0.1268 - loss: 2.8301\n",
      "Epoch 2/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.2841 - loss: 2.3794\n",
      "Epoch 3/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.3613 - loss: 2.1248\n",
      "Epoch 4/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4046 - loss: 1.9853\n",
      "Epoch 5/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4364 - loss: 1.8826\n",
      "Epoch 6/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4516 - loss: 1.8224\n",
      "Epoch 7/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4717 - loss: 1.7638\n",
      "Epoch 8/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4810 - loss: 1.7239\n",
      "Epoch 9/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4916 - loss: 1.6868\n",
      "Epoch 10/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.4941 - loss: 1.6644\n",
      "Epoch 11/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5110 - loss: 1.6226\n",
      "Epoch 12/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5111 - loss: 1.6081\n",
      "Epoch 13/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5173 - loss: 1.5878\n",
      "Epoch 14/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5215 - loss: 1.5768\n",
      "Epoch 15/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5294 - loss: 1.5504\n",
      "Epoch 16/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5339 - loss: 1.5407\n",
      "Epoch 17/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5387 - loss: 1.5228\n",
      "Epoch 18/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5398 - loss: 1.5121\n",
      "Epoch 19/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5446 - loss: 1.4905\n",
      "Epoch 20/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5460 - loss: 1.4870\n",
      "Epoch 21/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5526 - loss: 1.4702\n",
      "Epoch 22/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5549 - loss: 1.4629\n",
      "Epoch 23/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5516 - loss: 1.4626\n",
      "Epoch 24/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5581 - loss: 1.4440\n",
      "Epoch 25/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 1.4300\n",
      "Epoch 26/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5614 - loss: 1.4325\n",
      "Epoch 27/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5644 - loss: 1.4207\n",
      "Epoch 28/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5669 - loss: 1.4077\n",
      "Epoch 29/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5740 - loss: 1.3991\n",
      "Epoch 30/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5744 - loss: 1.3973\n",
      "Epoch 31/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5810 - loss: 1.3798\n",
      "Epoch 32/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5789 - loss: 1.3790\n",
      "Epoch 33/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5828 - loss: 1.3638\n",
      "Epoch 34/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5836 - loss: 1.3672\n",
      "Epoch 35/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5823 - loss: 1.3562\n",
      "Epoch 36/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5880 - loss: 1.3469\n",
      "Epoch 37/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5839 - loss: 1.3522\n",
      "Epoch 38/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5877 - loss: 1.3411\n",
      "Epoch 39/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5882 - loss: 1.3365\n",
      "Epoch 40/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5936 - loss: 1.3244\n",
      "Epoch 41/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5967 - loss: 1.3174\n",
      "Epoch 42/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5943 - loss: 1.3239\n",
      "Epoch 43/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5957 - loss: 1.3199\n",
      "Epoch 44/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5987 - loss: 1.3137\n",
      "Epoch 45/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.5969 - loss: 1.3082\n",
      "Epoch 46/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6012 - loss: 1.3007\n",
      "Epoch 47/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6036 - loss: 1.2859\n",
      "Epoch 48/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6042 - loss: 1.2855\n",
      "Epoch 49/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6032 - loss: 1.2897\n",
      "Epoch 50/50\n",
      "\u001b[1m1642/1642\u001b[0m \u001b[32m較較較較較較較較較較較較較較較較較較較較\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.6070 - loss: 1.2743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f720c249110>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires more training epochs for a more complicated model\n",
    "\n",
    "model.fit(padded_sequences, y_train_encoded, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa89a4-ab71-4d61-a4e7-ad8653c4254f",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "1. Why would we need positional encoding layers in a transformer model?\n",
    "2. Using the trainined model, write a function which takes the text of a tweet and output's the tweet's author.\n",
    "3. Update the transformer model from class to predict a tweet's number of likes instead of the author.\n",
    "4. Transformers, unlike previous models, require a lot more numerical stabalization techniques. Choose one of the methods we used today (layer normalization, batch normalization, residual connections). For the technique that you choose, do some independent research and try to learn what that technique is trying to do. Explain what you discovered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
